[[indices-split-index]]
== 拆分索引

拆分索引 API 允许您将现有索引拆分为新索引，其中每个原始主分片在新索引中可以被拆分为两个或多个主分片。

IMPORTANT:  `_split` API 要求使用特定的参数 `number_of_routing_shards` 来创建源索引，以便将来拆分。这个要求已在 Elasticsearch 7.0中被删除。


索引可以被拆分的次数（以及每个原始分片可以被拆分的分片数）由 `index.number_of_routing_shards` 设置决定。路由分片的数量指定了内部使用的哈希空间，以便在具有一致性哈希的分片中分发文档。例如，一个有5个分片的索引，如果 `number_of_routing_shards` 设置为 `30` (`5 x 2 x 3`) 则其可以被拆分为因子 `2` 或者 `3`。换句话说，它可以做如下拆分：

* `5` -> `10` -> `30`  （先分2，再分3）
* `5` -> `15` -> `30` （先分3，再分2）
* `5` -> `30` （分6）

[float]
=== 拆分是如何工作的？

拆分的工作原理如下：

* 首先，它创建一个新的目标索引，其定义与源索引相同，但主分片数量较多。

* 然后，它将源索引中的段硬链接到目标索引。（如果文件系统不支持硬链接，则会将所有段复制到新索引中，这是一个更耗时的过程。）

* 一旦创建了低层级的文件，所有文档将再次被“哈希”以删除属于不同分片的文档。

* 最后，恢复目标索引，就像是重新打开一个关闭的索引。

[float]
=== 为什么 Elasticsearch 不支持增量重新分片？

从 `N` 到 `N+1` 分片，又被称为增量重新分片，确实是许多键值存储引擎支持的功能。添加新的分片并将新数据推送到这个新分片不是一个好的选择：这可能会成为索引瓶颈，对于那些必须的查找、删除和更新请求来说，根据给定 `_id` 查找对应分片将变得相当复杂。这意味着我们需要使用不同的哈希方案来重新平衡现有数据。

键值存储最有效实现此目的的方法是使用一致性哈希。当分片的数量从 `N` 增加到 `N+1` 时，一致性哈希只需要重新定位键 `1/N` 次。然而 Elasticsearch 的存储、分片的单元是 Lucene 的索引。这种面向搜索的数据结构占据了 Lucene 索引的很大一部分。即使只有5%的文档，删除它们并在另一个分片上索引它们的代价通常比使用键值存储要高得多。如上一节所述，当通过多重因素增加分片数量时，这种成本是合理的：这允许 Elasticsearch 在本地执行拆分，从而允许在索引级别执行拆分，而不是重新索引那些需要移动的文档，以及使用硬链接进行文件复制。

在只新增数据的情况下，可以通过创建新索引并向其推送新数据，同时为读取操作添加覆盖旧索引和新索引的别名，从而获得更大的灵活性。假设新旧索引分别有 +M+ 和 +N+ 个分片，对比搜索具有 +M+N+ 个分片的索引没有额外开销。


[float]
=== 准备拆分索引

使用路由分片因子创建索引：

[source,sh]
--------------------------------------------------
PUT my_source_index
{
    "settings": {
        "index.number_of_shards" : 1,
        "index.number_of_routing_shards" : 2 <1>
    }
}
-------------------------------------------------
// CONSOLE

<1> 允许将索引拆分为两个分片，也就是说，它允许单个分割操作。

要拆分索引，必须先要将索引标记为只读，并且集群健康状态为 <<cluster-health,health>> `green` 。

可以通过以下请求来实现：

[source,js]
--------------------------------------------------
PUT /my_source_index/_settings
{
  "settings": {
    "index.blocks.write": true <1>
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

<1> 禁止对此索引的写操作，但是允许更改元数据，例如删除索引。

[float]
=== 拆分索引

要将索引 `my_source_index` 拆分到名为 `my_target_index` 的新索引，需要发出以下请求：

[source,js]
--------------------------------------------------
POST my_source_index/_split/my_target_index?copy_settings=true
{
  "settings": {
    "index.number_of_shards": 2
  }
}
--------------------------------------------------
// CONSOLE
// TEST[continued]

添加目标索引后，上述请求会立即返回集群状态 -- 它不等待拆分操作开始。

[IMPORTANT]
=====================================

只有满足以下要求的索引才能被拆分：

* 目标索引不存在。

* 索引的主分片必须小于目标索引的主分片数量。

* 目标索引中的主分片数必须是源索引中主分片数的一个因子。

* 拆分进程所在节点必须具有足够的可用磁盘空间，以容纳现有索引的第二个副本。

=====================================

`_split` API 类似于 <<indices-create-index, `create index` API>> 并接受目标索引的 `settings` 和  `aliases` 参数：

[source,js]
--------------------------------------------------
POST my_source_index/_split/my_target_index?copy_settings=true
{
  "settings": {
    "index.number_of_shards": 5 <1>
  },
  "aliases": {
    "my_search_indices": {}
  }
}
--------------------------------------------------
// CONSOLE
// TEST[s/^/PUT my_source_index\n{"settings": {"index.blocks.write": true, "index.number_of_routing_shards" : 5, "index.number_of_shards": "1"}}\n/]

<1> 目标索引中的分片数。其必须是源索引中分片数量的一个因子。


NOTE: 不能在 `_split` 请求中指定映射。

NOTE: 默认情况下，除了 `index.analysis` 、 `index.similarity` 和 `index.sort` 设置外，在拆分操作期间不会复制源索引上的索引设置。但是，可以通过将 URL 参数 `copy_settings = true` 添加到请求中，将源索引中的设置复制到目标索引。注意，`copy_settings` 不能被设置为 `false` 。参数 `copy_settings` 将在8.0.0中被删除。

deprecated[6.4.0，不复制设置将会被弃用，在7.x中复制设置将是默认行为]

[float]
=== 监控拆分进程

可以使用 <<cat-recovery,`_cat recovery`API>> 监控拆分进程，或者通过设置 `wait_for_status` 参数为 `yellow` 从而使用 <<cluster-health, `cluster health` API>> 来检查是否所有主分片都已经被分配。

在分配任何分片之前，只要目标索引已添加到群集状态，`_split` API 就会返回。此时，所有分片都处于 `unassigned` 状态。如果由于任何原因无法分配目标索引，则其主分片将保持 `unassigned`，直到可以在该节点上分配为止。

一旦分配了主分片，它就会进入 `initializing` 状态，并开始拆分。操作完成后，分片将变为 `active`。此时，Elasticsearch 将尝试分配副本，并可能决定将主分片重定位到另一个节点上。

[float]
=== 等待活动分片

因为拆分操作会创建一个新的索引来拆分分片，所以索引创建的 <<create-index-wait-for-active-shards,`waited active shards`>> 设置也适用于拆分索引操作。

