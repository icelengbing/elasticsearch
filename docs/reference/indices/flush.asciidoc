[[indices-flush]]
== 刷新

刷新 API 允许通过 API 刷新一个或者多个索引。索引的刷新进程通过将数据刷新到索引存储并清除内部事务日志，以便从索引中释放内存。默认情况下，Elasticsearch 使用内存探索式方法，以便根据需要自动触发刷新操作从而清理内存。

[source,js]
--------------------------------------------------
POST twitter/_flush
--------------------------------------------------
// CONSOLE
// TEST[setup:twitter]

[float]
[[flush-parameters]]
=== 请求参数

刷新 API 接收以下请求参数：

[horizontal]
`wait_if_ongoing`::  如果设置为“true”，则此次刷新操作需要先确认是否有另外一个刷新操作正在执行，如果有则当前刷新操作被阻塞，直到正在执行的刷新操作完成后才会继续。

`force`:: 是否可以强制刷新。例如在没有更改将提交到索引，当前也没有未提交的更改，而需要增加事物日志的 ID 时。这个参数就会非常有用（此设置可视为内部参数）

[float]
[[flush-multi-index]]
=== 多索引

刷新 API 可以通过一次调用应用于多个索引，甚至在 `_all` 索引上。

[source,js]
--------------------------------------------------
POST kimchy,elasticsearch/_flush

POST _flush
--------------------------------------------------
// CONSOLE
// TEST[s/^/PUT kimchy\nPUT elasticsearch\n/]

[[indices-synced-flush]]
=== 同步刷新

Elasticsearch 跟踪每个分片的索引活动。5分钟内未收到任何索引操作的分片会被自动标记为非活动状态。这为Elasticsearch 提供了减少分片消耗资源的机会，并且还执行了一种特殊的刷新，称为“同步刷新”。一次同步刷新会先执行一个正常刷新的动作，然后将生成的唯一标记（sync_id）添加到所有分片。

由于并没有在索引操作进行时添加同步 ID 标记，因此可以将这个操作用于快速检查两个分片的 lucene 索引是否相同。这个快速同步 ID 比较（如果存在）被用于在恢复或者重启期间跳过该过程的第一个也是代价最大的阶段。在这种情况下，不需要复制段文件，并且恢复动作中的事务日志重放可以立即开始启动。注意，由于同步 ID 标记与刷新一起应用，因此事务日志有可能是空的，从而加速了恢复。

这对于具有大量从不或者很少更新索引的场景特别有用。例如基于时间的数据，这种场景通常会产生大量索引，如果没有同步刷新标识其恢复会花费很长时间。

要检查分片是否有标记，可以在 <<indices-stats,indices stats>> API 返回的分片统计信息中查找 `commit` 部分：

[source,sh]
--------------------------------------------------
GET twitter/_stats?filter_path=**.commit&level=shards <1>
--------------------------------------------------
// CONSOLE
// TEST[s/^/PUT twitter\nPOST twitter\/_flush\/synced\n/]
<1> `filter_path` 用于减少返回响应内容的详细程度，是可选项。


返回类似于：

[source,js]
--------------------------------------------------
{
   "indices": {
      "twitter": {
         "shards": {
            "0": [
               {
                 "commit" : {
                   "id" : "3M3zkw2GHMo2Y4h4/KFKCg==",
                   "generation" : 3,
                   "user_data" : {
                     "translog_uuid" : "hnOG3xFcTDeoI_kvvvOdNA",
                     "history_uuid" : "XP7KDJGiS1a2fHYiFL5TXQ",
                     "local_checkpoint" : "-1",
                     "translog_generation" : "2",
                     "max_seq_no" : "-1",
                     "sync_id" : "AVvFY-071siAOuFGEO9P", <1>
                     "max_unsafe_auto_id_timestamp" : "-1"
                   },
                   "num_docs" : 0
                 }
               }
            ],
            "1": ...,
            "2": ...,
            "3": ...,
            "4": ...
         }
      }
   }
}
--------------------------------------------------
// TESTRESPONSE[s/"id" : "3M3zkw2GHMo2Y4h4\/KFKCg=="/"id": $body.indices.twitter.shards.0.0.commit.id/]
// TESTRESPONSE[s/"translog_uuid" : "hnOG3xFcTDeoI_kvvvOdNA"/"translog_uuid": $body.indices.twitter.shards.0.0.commit.user_data.translog_uuid/]
// TESTRESPONSE[s/"history_uuid" : "XP7KDJGiS1a2fHYiFL5TXQ"/"history_uuid": $body.indices.twitter.shards.0.0.commit.user_data.history_uuid/]
// TESTRESPONSE[s/"sync_id" : "AVvFY-071siAOuFGEO9P"/"sync_id": $body.indices.twitter.shards.0.0.commit.user_data.sync_id/]
// TESTRESPONSE[s/"1": \.\.\./"1": $body.indices.twitter.shards.1/]
// TESTRESPONSE[s/"2": \.\.\./"2": $body.indices.twitter.shards.2/]
// TESTRESPONSE[s/"3": \.\.\./"3": $body.indices.twitter.shards.3/]
// TESTRESPONSE[s/"4": \.\.\./"4": $body.indices.twitter.shards.4/]
<1> 同步标记 `sync id` 

[float]
=== 同步刷新 API

同步刷新 API 允许管理员手动启动同步刷新。这对于有计划的（滚动）重启集群尤其有用。通过它，您可以在停止索引后不用再等待默认5分钟后才自动启动的同步刷新空闲索引动作。

虽然方便，但使用这个 API 还有一些需要注意的事项：

1. 同步刷新是一种尽力而为的操作。分片上的任何索引动作都将会导致同步刷新失败。这意味着某些分片可以同步刷新，而另外的分片可能不行。具体请参阅以下内容。
2. 一旦再次刷新分片， `sync_id` 标记就会被删除。因为刷新动作会替换存储了标记的低级 lucene 提交点。事务日志中未提交的操作不会删除标记。在实践中，可以将索引上的任何索引操作视为删除标记，因为 Elasticsearch 可能在任一时刻触发刷新。


NOTE: 在正在进行索引的情况下进行同步刷新是没有不良影响的。空闲的分片将成功，非空闲的分片会失败。任何成功的分片未来都会有更快的恢复速度。

[source,sh]
--------------------------------------------------
POST twitter/_flush/synced
--------------------------------------------------
// CONSOLE
// TEST[setup:twitter]


响应的内容包含如下细节：同步刷新成功的分片数以及所有故障信息。

一个含有两个分片和一个副本的索引，当其所有分片成功完成同步刷新时的响应如下：

[source,js]
--------------------------------------------------
{
   "_shards": {
      "total": 2,
      "successful": 2,
      "failed": 0
   },
   "twitter": {
      "total": 2,
      "successful": 2,
      "failed": 0
   }
}
--------------------------------------------------
// TESTRESPONSE[s/"successful": 2/"successful": 1/]

以下是一个分片组由于挂起操作而失败时的情况：

[source,js]
--------------------------------------------------
{
   "_shards": {
      "total": 4,
      "successful": 2,
      "failed": 2
   },
   "twitter": {
      "total": 4,
      "successful": 2,
      "failed": 2,
      "failures": [
         {
            "shard": 1,
            "reason": "[2] ongoing operations on primary"
         }
      ]
   }
}
--------------------------------------------------
// NOTCONSOLE

NOTE: 由并发索引操作引发的同步刷新失败，将显示上述错误。而 HTTP 在这种情况下返回的状态代码将是  `409 CONFLICT` 。


有时，故障发生在特定某分片副本上。失败的副本将不符合快速恢复的条件，但那些成功的副本则不受影响。案例如下：

[source,js]
--------------------------------------------------
{
   "_shards": {
      "total": 4,
      "successful": 1,
      "failed": 1
   },
   "twitter": {
      "total": 4,
      "successful": 3,
      "failed": 1,
      "failures": [
         {
            "shard": 1,
            "reason": "unexpected error",
            "routing": {
               "state": "STARTED",
               "primary": false,
               "node": "SZNr2J_ORxKTLUCydGX4zA",
               "relocating_node": null,
               "shard": 1,
               "index": "twitter"
            }
         }
      ]
   }
}
--------------------------------------------------
// NOTCONSOLE

NOTE: 当分片副本无法同步刷新时，返回的 HTTP 状态代码将为 `409 CONFLICT` 。

同步刷新 API 可以应用于多个索引，甚至包括 `_all` 这样的索引。

[source,js]
--------------------------------------------------
POST kimchy,elasticsearch/_flush/synced

POST _flush/synced
--------------------------------------------------
// CONSOLE
