[[indices-analyze]]
== 分析

分析文本并返回拆分后的词元。

可以在不指定特定索引的情况下使用内置的某个分词器：

[source,js]
--------------------------------------------------
GET _analyze
{
  "analyzer" : "standard",
  "text" : "this is a test"
}
--------------------------------------------------
// CONSOLE

如果参数 text 是字符串数组，则其会被拆分为多值字段。

[source,js]
--------------------------------------------------
GET _analyze
{
  "analyzer" : "standard",
  "text" : ["this is a test", "the second text"]
}
--------------------------------------------------
// CONSOLE

或者使用分词器、词元过滤器和字符过滤器构建自定义瞬态分析器。词元过滤器可以使用较短的过滤器参数名称：

[source,js]
--------------------------------------------------
GET _analyze
{
  "tokenizer" : "keyword",
  "filter" : ["lowercase"],
  "text" : "this is a test"
}
--------------------------------------------------
// CONSOLE

[source,js]
--------------------------------------------------
GET _analyze
{
  "tokenizer" : "keyword",
  "filter" : ["lowercase"],
  "char_filter" : ["html_strip"],
  "text" : "this is a <b>test</b>"
}
--------------------------------------------------
// CONSOLE

deprecated[5.0.0，使用 `filter`/`char_filter` 替代 `filters`/`char_filters`，此外 `token_filters` 已被删除]

可以在请求正文中指定自定义分词器、词元过滤器和字符过滤器，如下所示：

[source,js]
--------------------------------------------------
GET _analyze
{
  "tokenizer" : "whitespace",
  "filter" : ["lowercase", {"type": "stop", "stopwords": ["a", "is", "this"]}],
  "text" : "this is a test"
}
--------------------------------------------------
// CONSOLE

它也可以在特定索引上运行：

[source,js]
--------------------------------------------------
GET analyze_sample/_analyze
{
  "text" : "this is a test"
}
--------------------------------------------------
// CONSOLE
// TEST[setup:analyze_sample]

上面的例子使用索引 `analyze_sample` 默认关联的分析器对文本 "this is a test" 进行分析，也可以为 `analyzer` 参数指定不同的分析器：

[source,js]
--------------------------------------------------
GET analyze_sample/_analyze
{
  "analyzer" : "whitespace",
  "text" : "this is a test"
}
--------------------------------------------------
// CONSOLE
// TEST[setup:analyze_sample]

分析器也可以基于某个字段映射，例如：

[source,js]
--------------------------------------------------
GET analyze_sample/_analyze
{
  "field" : "obj1.field1",
  "text" : "this is a test"
}
--------------------------------------------------
// CONSOLE
// TEST[setup:analyze_sample]

此时的分析动作是基于字段 `obj1.field1` 映射中的分析器配置（如果不是，采用默认索引分析器）。

[source,js]
--------------------------------------------------
GET analyze_sample/_analyze
{
  "normalizer" : "my_normalizer",
  "text" : "BaR"
}
--------------------------------------------------
// CONSOLE
// TEST[setup:analyze_sample]

或者通过使用词元过滤器和字符过滤器构建自定义瞬态规范化器。

[source,js]
--------------------------------------------------
GET _analyze
{
  "filter" : ["lowercase"],
  "text" : "BaR"
}
--------------------------------------------------
// CONSOLE

=== 解释分析

如果您想获得更多细节，请将 `explain` 设置为 `true` （默认为 `false` ）。这会输出每个词元的所有词元属性。您可以通过设置 `attributes` 选项来过滤要输出的令牌属性。

NOTE: 在 Lucene 中，附加细节信息的格式被标记为实验性的，未来可能会被改变。

[source,js]
--------------------------------------------------
GET _analyze
{
  "tokenizer" : "standard",
  "filter" : ["snowball"],
  "text" : "detailed output",
  "explain" : true,
  "attributes" : ["keyword"] <1>
}
--------------------------------------------------
// CONSOLE
<1> 设置“keyword”，仅输出“keyword”属性

请求返回结果如下：

[source,js]
--------------------------------------------------
{
  "detail" : {
    "custom_analyzer" : true,
    "charfilters" : [ ],
    "tokenizer" : {
      "name" : "standard",
      "tokens" : [ {
        "token" : "detailed",
        "start_offset" : 0,
        "end_offset" : 8,
        "type" : "<ALPHANUM>",
        "position" : 0
      }, {
        "token" : "output",
        "start_offset" : 9,
        "end_offset" : 15,
        "type" : "<ALPHANUM>",
        "position" : 1
      } ]
    },
    "tokenfilters" : [ {
      "name" : "snowball",
      "tokens" : [ {
        "token" : "detail",
        "start_offset" : 0,
        "end_offset" : 8,
        "type" : "<ALPHANUM>",
        "position" : 0,
        "keyword" : false <1>
      }, {
        "token" : "output",
        "start_offset" : 9,
        "end_offset" : 15,
        "type" : "<ALPHANUM>",
        "position" : 1,
        "keyword" : false <1>
      } ]
    } ]
  }
}
--------------------------------------------------
// TESTRESPONSE
<1> 只输出“keyword”属性，因为在请求中指定了“attributes”。
